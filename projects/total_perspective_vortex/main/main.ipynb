{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "# from conc_obj import EEGData\n",
    "from eegdata_multi import EEGData\n",
    "from utils.plt import plot_psd, plot_montage\n",
    "from utils.ica import plot_ica_comp\n",
    "\n",
    "# MNE imports\n",
    "import mne\n",
    "from mne.io.edf import read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Macros***\n",
    "\n",
    ">General use macros, importing JSON files to use as the configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = Path().resolve()\n",
    "folder = (script_path / \"../\").resolve()\n",
    "\n",
    "JSON_MAIN_PATH = script_path / \"config/config_main.json\"\n",
    "JSON_CSP_PATH = script_path / \"config/config_csp.json\"\n",
    "JSON_GRID_PATH = script_path / \"config/config_grid.json\"\n",
    "EVENTS_PATH = script_path / \"config/events.json\"\n",
    "\n",
    "with open(JSON_MAIN_PATH, \"r\") as f:\n",
    "    config_main = json.load(f)\n",
    "\n",
    "with open(JSON_CSP_PATH, \"r\") as f:\n",
    "    config_csp = json.load(f)\n",
    "    \n",
    "with open(JSON_GRID_PATH, \"r\") as f:\n",
    "    json_grid = json.load(f)\n",
    "\n",
    "VERBOSE = config_main['verbose'].lower() == 'true'\n",
    "\n",
    "L_FREQ = config_main['l_freq']\n",
    "H_FREQ = config_main['h_freq']\n",
    "\n",
    "N_SUBJECTS = config_main[\"n_subjects\"]\n",
    "N_COMPONENTS_ICA = config_main[\"n_components_ica\"]\n",
    "N_COMPONENTS_CSP = config_csp[\"n_components\"]\n",
    "N_COMPONENTS_PCA = N_COMPONENTS_CSP\n",
    "\n",
    "\"\"\"\n",
    "T0 corresponds to rest\n",
    "T1 corresponds to onset of motion (real or imagined) of\n",
    "the left fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "T2 corresponds to onset of motion (real or imagined) of\n",
    "the right fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "both feet (in runs 5, 6, 9, 10, 13, and 14)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialization of EEG object***\n",
    "\n",
    ">***(If the files are not locally stored, it will download them to the user system automatically)***\n",
    "\n",
    ">***Use of functions like .filter_data() also is obligatory if there is no data stored locally***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_obj = EEGData(config_main, config_csp, folder, verbose=VERBOSE)\n",
    "\n",
    "#* Filters data and plots PSD to see differences\n",
    "# eeg_obj.filter_data()\n",
    "# eeg_obj.plot_psd_ba_filt(verbose=VERBOSE)\n",
    "\n",
    "# eeg_obj.plot_psd(verbose=VERBOSE)\n",
    "\n",
    "#* Normalizes data\n",
    "# eeg_obj.normalize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic information and montage plotting in 2D & 3D**\n",
    "> ***The channel names can also be printed***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Plots different montages in 2D & 3D\n",
    "# data = eeg_obj.get_raw_h()\n",
    "# ch_names = data.info[\"ch_names\"] \n",
    "# plot_montage(eeg_obj.montage, ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ICA(Independent Component Analysys)**\n",
    "> ***The number of components that ICA will try to sort out can be changed, it is advised to use values in the range [15-45]***\n",
    "\n",
    "> ***Ocular artifacts are also removed, since they don't contribute to the muscular movement on this evaluation***\n",
    "\n",
    "> ***The components can also be plotted and ocular artifacts, EOG, will be clearly visible***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Computes ICA components\n",
    "# eeg_obj.decomp_ica(n_components=N_COMPONENTS_ICA, plt_show=True, verbose=VERBOSE)\n",
    "\n",
    "#* Plot components of ICA\n",
    "# plot_ica_comp(folder / config[\"path_ica_h\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify events & create Epochs**\n",
    "> ***The events used along with the JSON configuration will be crucial for the ML algorimths to work properly***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = eeg_obj.get_clean()\n",
    "events, _ = eeg_obj.get_events()\n",
    "\n",
    "event_l = config_csp[\"ev_blist_one\"]\n",
    "groupeve_dict = config_csp[\"event_dict_oph\"]\n",
    "\n",
    "event_dict1 = {key: value for key, value in groupeve_dict.items() if value in event_l[0]}\n",
    "print(\"Event dict. :\", event_dict1)\n",
    "\n",
    "print()\n",
    "epochs = mne.Epochs(data, events, event_id=event_dict1, tmin=0.3, tmax=3.3, baseline=None, verbose=VERBOSE)\n",
    "data = epochs.get_data()\n",
    "# data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "labels = epochs.events[:, -1]\n",
    "print(\"X:\", data.shape)\n",
    "print(\"Y:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pipeline***\n",
    "\n",
    ">The dimensionality reduction tools, classifications algorimths and signal processing (CSP) are included.\n",
    "\n",
    ">The default values/functions have been proved to be good over tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='rbf', C=100, gamma=2, probability=True)\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('svm', svm_clf), ('rf', rf_clf)], voting='soft')\n",
    "\n",
    "# Create a new pipeline for LDA\n",
    "pipeline = Pipeline([\n",
    "    #* Does not work (it needs reshaping)\n",
    "    # ('ica', FastICA(n_components=64)),\n",
    "\n",
    "    ('csp', CSP(n_components=N_COMPONENTS_CSP, reg='ledoit_wolf', log=True, norm_trace=False)),\n",
    "\n",
    "    ('scaler', StandardScaler()), #* StandardScaler works best\n",
    "    # ('scaler', MinMaxScaler()),\n",
    "    # ('scaler', RobustScaler()),\n",
    "\n",
    "    ('pca', PCA(n_components=N_COMPONENTS_PCA)),\n",
    "\n",
    "\t('voting_cs', ensemble)\n",
    "    #* Choose only one of the following classifiers\n",
    "\t# ('lda', LDA())\n",
    "    # ('svm', SVC(kernel='rbf', C=100, gamma=2))\n",
    "\t# ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the 3D pipeline to the transformed data\n",
    "# pipeline.fit(data, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GridSearch - Parameter selection***\n",
    "\n",
    ">Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    ">The default values have been tested. Performance varies from event type selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gridsearch import grid_finder, grid_search\n",
    "\n",
    "# grid = grid_finder(json_grid, 'svm', 'wide')\n",
    "# print(grid)\n",
    "# grid_search(data, labels, pipeline, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***K-Fold Training/Testing***\n",
    "\n",
    ">Split the data to train over different data sets, improves generalization.\n",
    "\n",
    ">Remove the last step of the pipeline to get the proccesed data without the ML CLF algorimth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeline.fit(data, labels)\n",
    "\n",
    "# Transform the data using the pipeline\n",
    "# Create a new pipeline excluding the last step\n",
    "pipeline_without_last_step = Pipeline(pipeline.steps[:-1])\n",
    "\n",
    "# Transform the data using the new pipeline\n",
    "processed_data = pipeline_without_last_step.transform(data)\n",
    "print(processed_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation - The good ol' tester***\n",
    "\n",
    ">We feed it the n_splits we chose on the K-folds along with the pipeline.\n",
    "\n",
    ">It ensures that the training/testing datasets are not mixed & calculates the average score over the K-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(pipeline, data, labels, cv=cv)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Processed data shape:\", processed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Divide the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "eeg_obj.train_model(X_train, y_train, pipeline)\n",
    "\n",
    "eeg_obj.pred(X_test, y_test, pipeline, n_preds=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving data locally**\n",
    "> ***Saving and loading data locally saves time and computational power***\n",
    "\n",
    "> ***Note that it is also needed to change the configuration at the JSON files to import local files***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Saves filtered and concatenated data for faster loading\n",
    "# eeg_obj.save_type_data(type=\"raw\", folder_path=folder)\n",
    "# eeg_obj.save_type_data(type=\"filtered\", folder_path=folder)\n",
    "# eeg_obj.save_type_data(type=\"norm\", folder_path=folder)\n",
    "# eeg_obj.save_type_data(type=\"ica\", folder_path=folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
