{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "# from conc_obj import EEGData\n",
    "from eegdata_multi import EEGData\n",
    "from utils.plt import plot_psd, plot_montage\n",
    "from utils.ica import plot_ica_comp\n",
    "\n",
    "# MNE imports\n",
    "import mne\n",
    "from mne.io.edf import read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Macros***\n",
    "\n",
    ">General use macros, importing JSON files to use as the configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = Path().resolve()\n",
    "folder = (script_path / \"../\").resolve()\n",
    "\n",
    "JSON_MAIN_PATH = script_path / \"config/config_main.json\"\n",
    "JSON_CSP_PATH = script_path / \"config/config_csp.json\"\n",
    "JSON_GRID_PATH = script_path / \"config/config_grid.json\"\n",
    "EVENTS_PATH = script_path / \"config/events.json\"\n",
    "\n",
    "with open(JSON_MAIN_PATH, \"r\") as f:\n",
    "    config_main = json.load(f)\n",
    "\n",
    "with open(JSON_CSP_PATH, \"r\") as f:\n",
    "    config_csp = json.load(f)\n",
    "    \n",
    "with open(JSON_GRID_PATH, \"r\") as f:\n",
    "    json_grid = json.load(f)\n",
    "\n",
    "VERBOSE = config_main['verbose'].lower() == 'true'\n",
    "\n",
    "L_FREQ = config_main['l_freq']\n",
    "H_FREQ = config_main['h_freq']\n",
    "\n",
    "N_SUBJECTS = config_main[\"n_subjects\"]\n",
    "N_COMPONENTS = config_main[\"n_components\"]\n",
    "\n",
    "\"\"\"\n",
    "T0 corresponds to rest\n",
    "T1 corresponds to onset of motion (real or imagined) of\n",
    "the left fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "T2 corresponds to onset of motion (real or imagined) of\n",
    "the right fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "both feet (in runs 5, 6, 9, 10, 13, and 14)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialization of EEG object***\n",
    "\n",
    ">***(If the files are not locally stored, it will download them to the user system automatically)***\n",
    "\n",
    ">***Use of functions like .filter_data() also is obligatory if there is no data stored locally***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_obj = EEGData(config_main, config_csp, folder, verbose=VERBOSE)\n",
    "\n",
    "#* Filters data and plots PSD to see differences\n",
    "# eeg_obj.filter_data()\n",
    "# eeg_obj.plot_psd_ba_filt(verbose=VERBOSE)\n",
    "\n",
    "# eeg_obj.plot_psd(verbose=VERBOSE)\n",
    "\n",
    "#* Normalizes data\n",
    "# eeg_obj.normalize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic information and montage plotting in 2D & 3D**\n",
    "> ***The channel names can also be printed***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Plots different montages in 2D & 3D\n",
    "# data = eeg_obj.get_raw_h()\n",
    "# ch_names = data.info[\"ch_names\"] \n",
    "# plot_montage(eeg_obj.montage, ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ICA(Independent Component Analysys)**\n",
    "> ***The number of components that ICA will try to sort out can be changed, it is advised to use values in the range [15-45]***\n",
    "\n",
    "> ***Ocular artifacts are also removed, since they don't contribute to the muscular movement on this evaluation***\n",
    "\n",
    "> ***The components can also be plotted and ocular artifacts, EOG, will be clearly visible***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Computes ICA components\n",
    "# eeg_obj.decomp_ica(n_components=N_COMPONENTS, plt_show=True, verbose=VERBOSE)\n",
    "\n",
    "#* Plot components of ICA\n",
    "# plot_ica_comp(folder / config[\"path_ica_h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = eeg_obj.get_filt()\n",
    "events, _ = eeg_obj.get_events()\n",
    "event_l = config_csp[\"ev_mlist_eight\"]\n",
    "groupeve_dict = config_csp[\"event_dict_h\"]\n",
    "event_dict1 = {key: value for key, value in groupeve_dict.items() if value in event_l[0]}\n",
    "print(event_dict1)\n",
    "\n",
    "epochs = mne.Epochs(data, events, event_id=event_dict1, tmin=0.3, tmax=3.3, baseline=None, verbose=VERBOSE)\n",
    "data = epochs.get_data()\n",
    "# data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "labels = epochs.events[:, -1]\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', C=100, gamma=2, probability=True)\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('svm', svm_clf), ('rf', rf_clf)], voting='soft')\n",
    "\n",
    "# Create a new pipeline for LDA\n",
    "pipeline = Pipeline([\n",
    "    # ('ica', FastICA(n_components=8)), ('pca')\n",
    "    ('csp', CSP(n_components=12, log=True, norm_trace=False)),\n",
    "    ('scaler', StandardScaler()), # StandardScaler works best\n",
    "\t('voting_cs', ensemble)\n",
    "\t# ('lda', LDA())\n",
    "    # ('svm', SVC(kernel='rbf', C=100, gamma=2))\n",
    "\t# ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the 3D pipeline to the transformed data\n",
    "# pipeline.fit(data, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GridSearch - Parameter selection***\n",
    "\n",
    ">Exhaustive search over specified parameter values for an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gridsearch import grid_finder, grid_search\n",
    "\n",
    "# grid = grid_finder(json_grid, 'svm', 'wide')\n",
    "# print(grid)\n",
    "# grid_search(data, labels, pipeline, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, data, labels, cv=cv)\n",
    "print(\"Cross-validation scores:\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving data locally**\n",
    "> ***Saving and loading data locally saves time and computational power***\n",
    "\n",
    "> ***Note that it is also needed to change the configuration at the JSON files to import local files***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Saves filtered and concatenated data for faster loading\n",
    "# eeg_obj.save_type_data(type=\"raw\", folder_path=folder)\n",
    "# eeg_obj.save_type_data(type=\"filtered\", folder_path=folder)\n",
    "# eeg_obj.save_type_data(type=\"norm\", folder_path=folder)\n",
    "# eeg_obj.save_type_data(type=\"ica\", folder_path=folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
