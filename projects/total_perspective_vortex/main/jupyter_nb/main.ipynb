{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "# from conc_obj import EEGData\n",
    "from eegdata_multi import EEGData\n",
    "from utils.plt import plot_psd, plot_montage\n",
    "from utils.ica import plot_ica_comp\n",
    "\n",
    "# MNE imports\n",
    "import mne\n",
    "from mne.io.edf import read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "# from mne.decoding import CSP\n",
    "from csp.CSPObj import CSP\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Macros***\n",
    "\n",
    ">General use macros, importing JSON files to use as the configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nT0 corresponds to rest\\nT1 corresponds to onset of motion (real or imagined) of\\nthe left fist (in runs 3, 4, 7, 8, 11, and 12)\\nboth fists (in runs 5, 6, 9, 10, 13, and 14)\\nT2 corresponds to onset of motion (real or imagined) of\\nthe right fist (in runs 3, 4, 7, 8, 11, and 12)\\nboth feet (in runs 5, 6, 9, 10, 13, and 14)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_path = Path().resolve()\n",
    "main_folder = (script_path / \"../\").resolve()\n",
    "proj_folder = (script_path / \"../../\").resolve()\n",
    "\n",
    "JSON_MAIN_PATH = main_folder / \"config/config_main.json\"\n",
    "JSON_CSP_PATH = main_folder / \"config/config_csp.json\"\n",
    "JSON_GRID_PATH = main_folder / \"config/config_grid.json\"\n",
    "EVENTS_PATH = main_folder / \"config/events.json\"\n",
    "\n",
    "with open(JSON_MAIN_PATH, \"r\") as f:\n",
    "    config_main = json.load(f)\n",
    "\n",
    "with open(JSON_CSP_PATH, \"r\") as f:\n",
    "    config_csp = json.load(f)\n",
    "    \n",
    "with open(JSON_GRID_PATH, \"r\") as f:\n",
    "    json_grid = json.load(f)\n",
    "\n",
    "VERBOSE = config_main['verbose'].lower() == 'true'\n",
    "\n",
    "L_FREQ = config_main['l_freq']\n",
    "H_FREQ = config_main['h_freq']\n",
    "\n",
    "N_SUBJECTS = config_main[\"n_subjects\"]\n",
    "N_COMPONENTS_ICA = config_main[\"n_components_ica\"]\n",
    "N_COMPONENTS_CSP = config_csp[\"n_components\"]\n",
    "N_COMPONENTS_PCA = N_COMPONENTS_CSP\n",
    "\n",
    "\"\"\"\n",
    "T0 corresponds to rest\n",
    "T1 corresponds to onset of motion (real or imagined) of\n",
    "the left fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "T2 corresponds to onset of motion (real or imagined) of\n",
    "the right fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "both feet (in runs 5, 6, 9, 10, 13, and 14)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialization of EEG object***\n",
    "\n",
    ">***(If the files are not locally stored, it will download them to the user system automatically)***\n",
    "\n",
    ">***Use of functions like .filter_data() also is obligatory if there is no data stored locally***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data:\n",
      "<Raw | sample_mmi_h_raw.fif, 64 x 2333120 (14582.0 s), ~1.11 GiB, data loaded> <Raw | sample_mmi_hf_raw.fif, 64 x 2333120 (14582.0 s), ~1.11 GiB, data loaded>\n",
      "<Raw | sample_mmi_h_filt_raw.fif, 64 x 2333120 (14582.0 s), ~1.11 GiB, data loaded> <Raw | sample_mmi_hf_filt_raw.fif, 64 x 2333120 (14582.0 s), ~1.11 GiB, data loaded>\n",
      "Reading /Users/Shared/42/ML/projects/total_perspective_vortex/data/ica/sample_mmi_h_ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Reading /Users/Shared/42/ML/projects/total_perspective_vortex/data/ica/sample_mmi_hf_ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "<ICA | raw data decomposition, method: fastica (fit in 85 iterations on 2333120 samples), 64 ICA components (64 PCA components available), channel types: eeg, 3 sources marked for exclusion> <ICA | raw data decomposition, method: fastica (fit in 80 iterations on 2333120 samples), 64 ICA components (64 PCA components available), channel types: eeg, 3 sources marked for exclusion>\n",
      "<ICA | raw data decomposition, method: fastica (fit in 85 iterations on 2333120 samples), 64 ICA components (64 PCA components available), channel types: eeg, 3 sources marked for exclusion> <ICA | raw data decomposition, method: fastica (fit in 80 iterations on 2333120 samples), 64 ICA components (64 PCA components available), channel types: eeg, 3 sources marked for exclusion>\n"
     ]
    }
   ],
   "source": [
    "eeg_obj = EEGData(config_main, config_csp, proj_folder, verbose=VERBOSE)\n",
    "\n",
    "#* Filters data and plots PSD to see differences\n",
    "# eeg_obj.filter_data()\n",
    "# eeg_obj.plot_psd_ba_filt(verbose=VERBOSE)\n",
    "\n",
    "# eeg_obj.plot_psd(verbose=VERBOSE)\n",
    "\n",
    "#* Normalizes data\n",
    "# eeg_obj.normalize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prediction - Loading testing data & ML models***\n",
    "\n",
    ">***If we don't want to train our model and want to make predictions or see any metric right away, we can load the data and call the methods right away.***\n",
    "\n",
    ">***Take into account that in order to change the events or any other parameter in the tools/methods loaded, you will have to train and save the entire model/data again!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_test, y_test = eeg_obj.load_models()\n",
    "# eeg_obj.pred(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic information and montage plotting in 2D & 3D**\n",
    "> ***The channel names can also be printed***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Plots different montages in 2D & 3D\n",
    "# data = eeg_obj.get_raw_h()\n",
    "# ch_names = data.info[\"ch_names\"] \n",
    "# plot_montage(eeg_obj.montage, ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ICA(Independent Component Analysys)**\n",
    "> ***The number of components that ICA will try to sort out can be changed, it is advised to use values in the range [15-45]***\n",
    "\n",
    "> ***Ocular artifacts are also removed, since they don't contribute to the muscular movement on this evaluation***\n",
    "\n",
    "> ***The components can also be plotted and ocular artifacts, EOG, will be clearly visible***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Computes ICA components\n",
    "# eeg_obj.decomp_ica(n_components=N_COMPONENTS_ICA, plt_show=True, verbose=VERBOSE)\n",
    "\n",
    "#* Plot components of ICA\n",
    "# plot_ica_comp(folder / config[\"path_ica_h\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify events & create Epochs**\n",
    "> ***The events used along with the JSON configuration will be crucial for the ML algorimths to work properly***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event dict. : {'do/feet': 1, 'do/hands': 2, 'imagine/feet': 3, 'imagine/hands': 4, 'rest': 5}\n",
      "\n",
      "Using data from preloaded Raw for 3540 events and 481 original time points ...\n",
      "0 bad epochs dropped\n",
      "X: (3540, 64, 481)\n",
      "Y: (3540,)\n"
     ]
    }
   ],
   "source": [
    "data, _ = eeg_obj.get_clean()\n",
    "events, _ = eeg_obj.get_events()\n",
    "\n",
    "event_l = config_csp[\"ev_mlist_eight\"]\n",
    "groupeve_dict = config_csp[\"event_dict_hf\"]\n",
    "\n",
    "event_dict1 = {key: value for key, value in groupeve_dict.items() if value in event_l[0]}\n",
    "print(\"Event dict. :\", event_dict1)\n",
    "\n",
    "print()\n",
    "epochs = mne.Epochs(data, events, event_id=event_dict1, tmin=0.3, tmax=3.3, baseline=None, verbose=VERBOSE)\n",
    "data = epochs.get_data()\n",
    "# data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "labels = epochs.events[:, -1]\n",
    "print(\"X:\", data.shape)\n",
    "print(\"Y:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pipeline***\n",
    "\n",
    ">The dimensionality reduction tools, classifications algorimths and signal processing (CSP) are included.\n",
    "\n",
    ">The default values/functions have been proved to be good over tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='rbf', C=100, gamma=2, probability=True)\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('svm', svm_clf), ('rf', rf_clf)], voting='soft')\n",
    "\n",
    "# Create a new pipeline for LDA\n",
    "pipeline = Pipeline([\n",
    "    #* Does not work (it needs reshaping)\n",
    "    # ('ica', FastICA(n_components=64)),\n",
    "\n",
    "    ('csp', CSP(n_components=N_COMPONENTS_CSP, reg='ledoit_wolf', log=True, norm_trace=False)),\n",
    "\n",
    "    ('scaler', StandardScaler()), #* StandardScaler works best\n",
    "    # ('scaler', MinMaxScaler()),\n",
    "    # ('scaler', RobustScaler()),\n",
    "\n",
    "    ('pca', PCA(n_components=N_COMPONENTS_PCA)),\n",
    "\n",
    "\t('voting_cs', ensemble)\n",
    "    #* Choose only one of the following classifiers\n",
    "\t# ('lda', LDA())\n",
    "    # ('svm', SVC(kernel='rbf', C=100, gamma=2))\n",
    "\t# ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the 3D pipeline to the transformed data\n",
    "# pipeline.fit(data, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GridSearch - Parameter selection***\n",
    "\n",
    ">Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    ">The default values have been tested. Performance varies from event type selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gridsearch import grid_finder, grid_search\n",
    "\n",
    "# grid = grid_finder(json_grid, 'svm', 'wide')\n",
    "# print(grid)\n",
    "# grid_search(data, labels, pipeline, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***K-Fold Training/Testing***\n",
    "\n",
    ">Split the data to train over different data sets, improves generalization.\n",
    "\n",
    ">Remove the last step of the pipeline to get the proccesed data without the ML CLF algorimth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3540, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeline.fit(data, labels)\n",
    "\n",
    "# Transform the data using the pipeline\n",
    "# Create a new pipeline excluding the last step\n",
    "pipeline_without_last_step = Pipeline(pipeline.steps[:-1])\n",
    "\n",
    "# Transform the data using the new pipeline\n",
    "processed_data = pipeline_without_last_step.transform(data)\n",
    "print(processed_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation - The good ol' tester***\n",
    "\n",
    ">We feed it the n_splits we chose on the K-folds along with the pipeline.\n",
    "\n",
    ">It ensures that the training/testing datasets are not mixed & calculates the average score over the K-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.89548023 0.87429379 0.88559322 0.87288136 0.90677966]\n",
      "Processed data shape: (3540, 12)\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(pipeline, data, labels, cv=cv)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Processed data shape:\", processed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy LDA: 0.5709745762711864\n",
      "Train Accuracy SVM: 1.0\n",
      "Train Accuracy RF: 1.0\n",
      "\n",
      "epoch nb: [prediction] [truth] equal?\n",
      "epoch 000:\t[5]\t\t[5]  True\n",
      "epoch 001:\t[1]\t\t[1]  True\n",
      "epoch 002:\t[5]\t\t[5]  True\n",
      "epoch 003:\t[5]\t\t[5]  True\n",
      "epoch 004:\t[5]\t\t[5]  True\n",
      "epoch 005:\t[5]\t\t[5]  True\n",
      "epoch 006:\t[5]\t\t[5]  True\n",
      "epoch 007:\t[5]\t\t[5]  True\n",
      "epoch 008:\t[5]\t\t[5]  True\n",
      "epoch 009:\t[1]\t\t[1]  True\n",
      "epoch 010:\t[4]\t\t[4]  True\n",
      "epoch 011:\t[5]\t\t[5]  True\n",
      "epoch 012:\t[3]\t\t[3]  True\n",
      "epoch 013:\t[5]\t\t[5]  True\n",
      "epoch 014:\t[5]\t\t[5]  True\n",
      "epoch 015:\t[3]\t\t[3]  True\n",
      "epoch 016:\t[1]\t\t[1]  True\n",
      "epoch 017:\t[5]\t\t[5]  True\n",
      "epoch 018:\t[5]\t\t[5]  True\n",
      "epoch 019:\t[5]\t\t[5]  True\n",
      "epoch 020:\t[3]\t\t[3]  True\n",
      "epoch 021:\t[2]\t\t[2]  True\n",
      "epoch 022:\t[5]\t\t[5]  True\n",
      "epoch 023:\t[5]\t\t[5]  True\n",
      "epoch 024:\t[3]\t\t[3]  True\n",
      "epoch 025:\t[5]\t\t[3]  False\n",
      "epoch 026:\t[5]\t\t[5]  True\n",
      "epoch 027:\t[5]\t\t[5]  True\n",
      "epoch 028:\t[5]\t\t[5]  True\n",
      "epoch 029:\t[5]\t\t[5]  True\n",
      "epoch 030:\t[1]\t\t[1]  True\n",
      "\n",
      "LDA Accuracy: 0.5932203389830508\n",
      "SVM Accuracy: 0.8983050847457628\n",
      "Random Forest Accuracy: 0.9265536723163842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#* Divide the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "eeg_obj.train_model(X_train, y_train)\n",
    "\n",
    "eeg_obj.pred(X_test, y_test, n_preds=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving data locally**\n",
    "> ***Saving and loading data locally saves time and computational power***\n",
    "\n",
    "> ***Note that it is also needed to change the configuration at the JSON files to import local files***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Saves filtered and concatenated data for faster loading\n",
    "# eeg_obj.save_type_data(type=\"raw\")\n",
    "# eeg_obj.save_type_data(type=\"filtered\")\n",
    "# eeg_obj.save_type_data(type=\"norm\")\n",
    "# eeg_obj.save_type_data(type=\"ica\")\n",
    "# eeg_obj.save_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
