{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# from conc_obj import EEGData\n",
    "from eegdata_multi import EEGData\n",
    "from utils.plt import plot_psd, plot_montage\n",
    "from utils.ica import plot_ica_comp\n",
    "\n",
    "# MNE imports\n",
    "import mne\n",
    "from mne.io.edf import read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Macros***\n",
    "\n",
    ">General use macros, importing JSON files to use as the configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = Path().resolve()\n",
    "main_folder = (script_path / \"../\").resolve()\n",
    "proj_folder = (script_path / \"../../\").resolve()\n",
    "\n",
    "JSON_MAIN_PATH = main_folder / \"config/config_main.json\"\n",
    "JSON_CSP_PATH = main_folder / \"config/config_csp.json\"\n",
    "JSON_GRID_PATH = main_folder / \"config/config_grid.json\"\n",
    "EVENTS_PATH = main_folder / \"config/events.json\"\n",
    "\n",
    "with open(JSON_MAIN_PATH, \"r\") as f:\n",
    "    config_main = json.load(f)\n",
    "\n",
    "with open(JSON_CSP_PATH, \"r\") as f:\n",
    "    config_csp = json.load(f)\n",
    "\n",
    "VERBOSE = config_main['verbose'].lower() == 'true'\n",
    "\n",
    "L_FREQ = config_main['l_freq']\n",
    "H_FREQ = config_main['h_freq']\n",
    "\n",
    "N_SUBJECTS = config_main[\"n_subjects\"]\n",
    "N_COMPONENTS_ICA = config_main[\"n_components_ica\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialization of EEG object***\n",
    "\n",
    ">***(If the files are not locally stored, it will download them to the user system automatically)***\n",
    "\n",
    ">***Use of functions like .filter_data() also is obligatory if there is no data stored locally***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data:\n",
      "<Raw | sample_mmi_h_raw.fif, 64 x 2333120 (14582.0 s), ~1.11 GiB, data loaded> <Raw | sample_mmi_hf_raw.fif, 64 x 2333120 (14582.0 s), ~1.11 GiB, data loaded>\n",
      "<Raw | sample_mmi_h_filt_raw.fif, 64 x 2333120 (14582.0 s), ~1.11 GiB, data loaded> <Raw | sample_mmi_hf_filt_raw.fif, 64 x 2333120 (14582.0 s), ~1.11 GiB, data loaded>\n",
      "Reading /Users/Shared/42/ML/projects/total_perspective_vortex/data/ica/sample_mmi_h_ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Reading /Users/Shared/42/ML/projects/total_perspective_vortex/data/ica/sample_mmi_hf_ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "<ICA | raw data decomposition, method: fastica (fit in 85 iterations on 2333120 samples), 64 ICA components (64 PCA components available), channel types: eeg, 3 sources marked for exclusion> <ICA | raw data decomposition, method: fastica (fit in 80 iterations on 2333120 samples), 64 ICA components (64 PCA components available), channel types: eeg, 3 sources marked for exclusion>\n",
      "<ICA | raw data decomposition, method: fastica (fit in 85 iterations on 2333120 samples), 64 ICA components (64 PCA components available), channel types: eeg, 3 sources marked for exclusion> <ICA | raw data decomposition, method: fastica (fit in 80 iterations on 2333120 samples), 64 ICA components (64 PCA components available), channel types: eeg, 3 sources marked for exclusion>\n"
     ]
    }
   ],
   "source": [
    "eeg_obj = EEGData(config_main, config_csp, proj_folder, verbose=VERBOSE)\n",
    "# eeg_obj.save_type_data(type=\"events\", folder_path=folder, verbose=VERBOSE)\n",
    "\n",
    "#* Filters data and plots PSD to see differences\n",
    "# eeg_obj.filter_data()\n",
    "# eeg_obj.plot_psd_ba_filt(verbose=VERBOSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prediction - Loading testing data & ML models***\n",
    "\n",
    ">***If we don't want to train our model and want to make predictions or see any metric right away, we can load the data and call the methods right away.***\n",
    "\n",
    ">***Take into account that in order to change the events or any other parameter in the tools/methods loaded, you will have to train and save the entire model/data again!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_test, y_test = eeg_obj.load_models()\n",
    "# eeg_obj.pred(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic information and montage plotting in 2D & 3D**\n",
    "> ***The channel names can also be printed***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Plots different montages in 2D & 3D\n",
    "# data = eeg_obj.get_raw_h()\n",
    "\n",
    "# ch_names = data.info[\"ch_names\"] \n",
    "\n",
    "# plot_montage(eeg_obj.montage, ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ICA(Independent Component Analysys)**\n",
    "> ***The number of components that ICA will try to sort out can be changed, it is advised to use values in the range [16-64]***\n",
    "\n",
    "> ***Ocular artifacts are also removed, since they don't contribute to the muscular movement on this evaluation***\n",
    "\n",
    "> ***The components can also be plotted and ocular artifacts, EOG, will be clearly visible***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Computes ICA components ( If loaded locally do not use! )\n",
    "# eeg_obj.decomp_ica(n_components=N_COMPONENTS_ICA, plt_show=True, verbose=VERBOSE)\n",
    "\n",
    "#* Plot components of ICA\n",
    "# plot_ica_comp(folder / config_main[\"path_ica_h\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify events & create Epochs**\n",
    "> ***The events used along with the JSON configuration will be crucial for the ML algorimths to work properly***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event dict. :  {'do/left_hand': 1, 'do/right_hand': 2, 'imagine/left_hand': 3, 'imagine/right_hand': 4, 'rest': 5}\n",
      "\n",
      "Using data from preloaded Raw for 3540 events and 433 original time points ...\n",
      "0 bad epochs dropped\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#* Loads cleaned data and events\n",
    "data_h, data_hf = eeg_obj.get_clean()\n",
    "events_h, events_hf = eeg_obj.get_events()\n",
    "\n",
    "#* Creates epochs and frequency bands\n",
    "ev_list = config_csp[\"ev_mlist_eight\"]\n",
    "epochs, freq_bands = eeg_obj.crt_epochs(data_h, events_h, ev_list, \"hands\", verbose=VERBOSE)\n",
    "\n",
    "print()\n",
    "epochs_data = epochs.get_data()\n",
    "labels = epochs.events[:, -1]\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CSP - Common Spatial Pattern(s)***\n",
    "\n",
    ">Separates multivariate signals into additive components which have maximum differences in variance between two windows.\n",
    "\n",
    ">Specially used on MEG & EEG datasets for motor imagery decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3540, 64, 433) (3540,)\n",
      "Shape after CSP: (3540, 48)\n"
     ]
    }
   ],
   "source": [
    "N_COMPONENTS_CSP = config_csp[\"n_components\"]\n",
    "features, csp = eeg_obj.csp(epochs_data, labels, freq_bands, epochs.info, verbose=VERBOSE)\n",
    "\n",
    "#* Only use plot_patters if you are not using PCA before\n",
    "# csp.plot_patterns(epochs.info, ch_type=\"eeg\", units=\"Patterns (AU)\", size=1.5)\n",
    "\n",
    "#* Displays the performance of CSP along classifiers through a timeline\n",
    "# eeg_obj.csp_performance(epochs, labels, clf_type='svm', verbose=False)\n",
    "\n",
    "#* Two step CSP\n",
    "# features, labels = eeg_obj.two_step_csp(epochs1, epochs2, freq_bands, verbose=VERBOSE)\n",
    "\n",
    "#* Verify any shape\n",
    "print(\"Shape after CSP:\", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize and apply PCA(Principal Component Analysis)**\n",
    "> ***Faster computation, training, testing, ...***\n",
    "\n",
    "> ***Reduces the risk of over-fitting***\n",
    "\n",
    "> ***Improves the accuracy of classification ML algorimths***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Normalizes data\n",
    "# features_norm = eeg_obj.normalize(features)\n",
    "features_norm = StandardScaler().fit_transform(features)\n",
    "\n",
    "#* Reduce dimensionality (PCA)\n",
    "# features_pca = eeg_obj.pca(features_norm)\n",
    "pca = PCA(n_components=N_COMPONENTS_CSP)\n",
    "features_pca = pca.fit_transform(features_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GridSearch - Parameter selection***\n",
    "\n",
    ">Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    ">The default values have been tested. Performance varies from event type selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gridsearch import grid_finder, grid_search\n",
    "\n",
    "# grid = grid_finder(json_grid, 'svm', 'wide')\n",
    "# print(grid)\n",
    "# grid_search(data, labels, pipeline, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pipeline***\n",
    "\n",
    ">The dimensionality reduction tools, classifications algorimths and signal processing (CSP) are included.\n",
    "\n",
    ">The default values/functions have been proved to be good over tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pipeline import crt_pipeline\n",
    "\n",
    "pipeline = crt_pipeline(clf=True, voting='soft')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation - The good ol' tester***\n",
    "\n",
    ">We can choose the n_splits along with the pipeline. (Can be both customized before)\n",
    "\n",
    ">It ensures that the training/testing datasets are not mixed & calculates the average score over the K-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89548023 0.88559322 0.89124294 0.87853107 0.91242938]\n",
      "Mean score: 0.8926553672316384\n",
      "{'fit_time': array([2.20092392, 2.25810194, 2.21403909, 2.19763708, 2.19787502]), 'score_time': array([0.05967522, 0.0770812 , 0.06047201, 0.05854392, 0.05881786]), 'test_score': array([0.89548023, 0.88559322, 0.89124294, 0.87853107, 0.91242938]), 'train_score': array([1., 1., 1., 1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "#* Trains and evaluates model\n",
    "scores = eeg_obj.cross_val(features_pca, labels, pipeline, n_splits=5)\n",
    "print(\"Mean score:\", np.mean(scores))\n",
    "\n",
    "scores = eeg_obj.cross_validate(features_pca, labels, pipeline, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy LDA: 0.5264830508474576\n",
      "Train Accuracy SVM: 1.0\n",
      "Train Accuracy RF: 1.0\n",
      "\n",
      "epoch nb: [prediction] [truth] equal?\n",
      "epoch 000:\t[5]\t\t[5]  True\n",
      "epoch 001:\t[1]\t\t[1]  True\n",
      "epoch 002:\t[5]\t\t[5]  True\n",
      "epoch 003:\t[5]\t\t[5]  True\n",
      "epoch 004:\t[5]\t\t[5]  True\n",
      "epoch 005:\t[5]\t\t[5]  True\n",
      "epoch 006:\t[5]\t\t[5]  True\n",
      "epoch 007:\t[5]\t\t[5]  True\n",
      "epoch 008:\t[5]\t\t[5]  True\n",
      "epoch 009:\t[1]\t\t[1]  True\n",
      "epoch 010:\t[4]\t\t[4]  True\n",
      "epoch 011:\t[5]\t\t[5]  True\n",
      "epoch 012:\t[3]\t\t[3]  True\n",
      "epoch 013:\t[5]\t\t[5]  True\n",
      "epoch 014:\t[5]\t\t[5]  True\n",
      "epoch 015:\t[3]\t\t[3]  True\n",
      "epoch 016:\t[1]\t\t[1]  True\n",
      "epoch 017:\t[5]\t\t[5]  True\n",
      "epoch 018:\t[5]\t\t[5]  True\n",
      "epoch 019:\t[5]\t\t[5]  True\n",
      "epoch 020:\t[3]\t\t[3]  True\n",
      "epoch 021:\t[2]\t\t[2]  True\n",
      "epoch 022:\t[5]\t\t[5]  True\n",
      "epoch 023:\t[5]\t\t[5]  True\n",
      "epoch 024:\t[3]\t\t[3]  True\n",
      "epoch 025:\t[5]\t\t[3]  False\n",
      "epoch 026:\t[5]\t\t[5]  True\n",
      "epoch 027:\t[5]\t\t[5]  True\n",
      "epoch 028:\t[5]\t\t[5]  True\n",
      "epoch 029:\t[5]\t\t[5]  True\n",
      "epoch 030:\t[1]\t\t[1]  True\n",
      "\n",
      "LDA Accuracy: 0.5677966101694916\n",
      "SVM Accuracy: 0.8983050847457628\n",
      "Random Forest Accuracy: 0.9081920903954802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#* Divide the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_pca, labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "eeg_obj.train_model(X_train, y_train)\n",
    "\n",
    "eeg_obj.pred(X_test, y_test, n_preds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Saves filtered and concatenated data for faster loading\n",
    "# eeg_obj.save_type_data(type=\"raw\")\n",
    "# eeg_obj.save_type_data(type=\"filtered\")\n",
    "# eeg_obj.save_type_data(type=\"ica\")\n",
    "# eeg_obj.save_type_data(type=\"clean\")\n",
    "# eeg_obj.save_type_data(type=\"epochs\")\n",
    "# eeg_obj.save_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
